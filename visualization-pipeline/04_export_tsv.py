#!/usr/bin/env -S uv run
"""
Export embeddings to TSV format for TensorFlow Projector.

This script:
1. Loads UMAP coordinates and metadata
2. Exports vectors.tsv (UMAP coordinates)
3. Exports metadata.tsv (labels and attributes)
4. Creates a README with usage instructions
"""

# /// script
# requires-python = ">=3.11"
# dependencies = [
#     "numpy>=1.26.0",
#     "pandas>=2.1.0",
# ]
# ///

import sys
from pathlib import Path

import numpy as np
import pandas as pd


def export_vectors_tsv(coordinates: np.ndarray, output_path: Path):
    """
    Export coordinate vectors to TSV format.

    Format: tab-separated values, no header
    Each row: coord1\tcoord2\t[coord3]
    """
    print(f"Exporting vectors to: {output_path}")

    with open(output_path, 'w') as f:
        for row in coordinates:
            # Format each coordinate with 6 decimal places
            formatted = '\t'.join(f'{x:.6f}' for x in row)
            f.write(f'{formatted}\n')

    print(f"✓ Exported {len(coordinates)} vectors")


def export_metadata_tsv(metadata: pd.DataFrame, output_path: Path):
    """
    Export metadata to TSV format.

    Format: tab-separated values with header
    Columns: label, source_column, usage_count, etc.
    """
    print(f"Exporting metadata to: {output_path}")

    # Select and order columns for TensorFlow Projector
    columns_to_export = [
        'label',
        'source_table',
        'source_column',
        'usage_count',
    ]

    # Verify columns exist
    available_columns = [col for col in columns_to_export if col in metadata.columns]

    if 'label' not in available_columns:
        # Fall back to 'value' column if 'label' doesn't exist
        if 'value' in metadata.columns:
            metadata = metadata.rename(columns={'value': 'label'})
            available_columns = ['label'] + [col for col in columns_to_export[1:] if col in metadata.columns]

    export_df = metadata[available_columns]

    # Clean up text for TSV format
    for col in export_df.select_dtypes(include=['object']).columns:
        # Replace tabs and newlines
        export_df[col] = export_df[col].astype(str).str.replace('\t', ' ').str.replace('\n', ' ')

    # Export to TSV
    export_df.to_csv(output_path, sep='\t', index=False)

    print(f"✓ Exported {len(export_df)} metadata rows")
    print(f"  Columns: {', '.join(export_df.columns)}")


def create_readme(output_dir: Path, num_vectors: int, dimensions: int):
    """
    Create README with usage instructions.
    """
    readme_path = output_dir / "README.md"

    content = f"""# TensorFlow Projector Export

This directory contains embeddings exported for visualization in TensorFlow Projector.

## Files

- `vectors_2d.tsv` - 2D UMAP coordinates ({num_vectors} vectors)
- `vectors_3d.tsv` - 3D UMAP coordinates ({num_vectors} vectors)
- `metadata.tsv` - Labels and attributes for each vector

## Usage

### Option 1: TensorFlow Projector (Online)

1. Go to https://projector.tensorflow.org/
2. Click "Load" in the top-left
3. Upload both files:
   - `vectors_2d.tsv` or `vectors_3d.tsv` (as "Load data")
   - `metadata.tsv` (as "Load metadata")
4. The visualization will appear automatically

### Option 2: Local TensorBoard

```bash
# Install TensorBoard
pip install tensorboard

# Create projector config
cat > projector_config.pbtxt <<EOF
embeddings {{
  tensor_name: "Zebra H2B Embeddings"
  tensor_path: "vectors_2d.tsv"
  metadata_path: "metadata.tsv"
}}
EOF

# Run TensorBoard
tensorboard --logdir=. --port=6006

# Open in browser: http://localhost:6006
```

## Visualization Tips

1. **Color by metadata**: Use the "Color by" dropdown to color points by source_column or usage_count
2. **Search**: Type a label in the search box to highlight specific embeddings
3. **Nearest neighbors**: Click a point to see its nearest neighbors
4. **Clustering**: Similar labels should cluster together
5. **Isolate points**: Select points and use "Isolate selection" to focus on specific clusters

## Data Details

- **Total embeddings**: {num_vectors}
- **Original dimension**: 1536d
- **Reduced dimensions**: {dimensions}D (via UMAP)
- **UMAP parameters**:
  - n_neighbors: 20
  - min_dist: 0.1
  - metric: cosine
  - random_state: 42

## Expected Patterns

Similar labels should form clusters:
- Memory/RAM/Storage variations
- WiFi/Wireless/802.11 variations
- Battery/Power variations
- Display/Screen variations

Use this visualization to identify:
1. Duplicate/near-duplicate labels
2. Case sensitivity issues (BATTERY vs Battery)
3. Typos and encoding errors
4. Semantic groups that should be normalized

## Generated

This export was generated by the zebra-h2b-audit-v2 visualization pipeline.
"""

    readme_path.write_text(content)
    print(f"✓ Created README: {readme_path}")


def main():
    """Main execution flow."""
    print("=" * 80)
    print("TSV EXPORT FOR TENSORFLOW PROJECTOR")
    print("=" * 80)
    print()

    # Load data
    data_dir = Path(__file__).parent / "data"
    metadata_path = data_dir / "metadata.csv"
    umap_2d_path = data_dir / "umap_2d.npy"
    umap_3d_path = data_dir / "umap_3d.npy"

    if not all([metadata_path.exists(), umap_2d_path.exists(), umap_3d_path.exists()]):
        print("❌ Error: Required files not found")
        print("Please run the previous scripts first:")
        print("  1. 01_extract_embeddings.py")
        print("  2. 02_reduce_with_umap.py")
        sys.exit(1)

    print("Loading data...")
    metadata = pd.read_csv(metadata_path)
    umap_2d = np.load(umap_2d_path)
    umap_3d = np.load(umap_3d_path)

    print(f"✓ Loaded metadata: {metadata.shape}")
    print(f"✓ Loaded 2D coordinates: {umap_2d.shape}")
    print(f"✓ Loaded 3D coordinates: {umap_3d.shape}")
    print()

    # Create output directory
    output_dir = Path(__file__).parent / "tsv_export"
    output_dir.mkdir(exist_ok=True)
    print(f"Output directory: {output_dir}")
    print()

    # Export 2D vectors
    print("-" * 80)
    print("EXPORTING 2D VECTORS")
    print("-" * 80)
    vectors_2d_path = output_dir / "vectors_2d.tsv"
    export_vectors_tsv(umap_2d, vectors_2d_path)
    print()

    # Export 3D vectors
    print("-" * 80)
    print("EXPORTING 3D VECTORS")
    print("-" * 80)
    vectors_3d_path = output_dir / "vectors_3d.tsv"
    export_vectors_tsv(umap_3d, vectors_3d_path)
    print()

    # Export metadata
    print("-" * 80)
    print("EXPORTING METADATA")
    print("-" * 80)
    metadata_path_tsv = output_dir / "metadata.tsv"
    export_metadata_tsv(metadata, metadata_path_tsv)
    print()

    # Create README
    print("-" * 80)
    print("CREATING README")
    print("-" * 80)
    create_readme(output_dir, len(metadata), 2)
    print()

    # Summary
    print("=" * 80)
    print("EXPORT COMPLETE")
    print("=" * 80)
    print(f"\nExported files:")
    print(f"  - {vectors_2d_path}")
    print(f"  - {vectors_3d_path}")
    print(f"  - {metadata_path_tsv}")
    print(f"  - {output_dir / 'README.md'}")
    print()

    # File sizes
    size_2d = vectors_2d_path.stat().st_size / 1024
    size_3d = vectors_3d_path.stat().st_size / 1024
    size_meta = metadata_path_tsv.stat().st_size / 1024

    print(f"File sizes:")
    print(f"  - vectors_2d.tsv: {size_2d:.1f} KB")
    print(f"  - vectors_3d.tsv: {size_3d:.1f} KB")
    print(f"  - metadata.tsv: {size_meta:.1f} KB")
    print()

    print("Next steps:")
    print("  1. Open https://projector.tensorflow.org/")
    print("  2. Click 'Load' and upload the TSV files")
    print("  3. Explore the visualization to identify similar labels")
    print()
    print("✓ All done!")


if __name__ == "__main__":
    main()
